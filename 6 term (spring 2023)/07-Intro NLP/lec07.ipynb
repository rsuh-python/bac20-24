{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dc5c4e-a5a6-478d-b688-1454510a0015",
   "metadata": {},
   "source": [
    "### Теоретические основы КЛ в связи с программированием. Токенизация и сегментация по предложениям"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e058bd9-908a-4246-8291-b919ee876ab7",
   "metadata": {},
   "source": [
    "Современную лингвистику можно разделить на три больших области, которые тесно (более или менее) взаимодействуют друг с другом: это собственно теоретическая лингвистика, компьютерная лингвистика и NLP (natural language processing). В чем разница между этими тремя областями, чем они занимаются? Подробно можно посмотреть лекцию В.П. Селегея, которую он читал у нас однажды на открытом семинаре: [Компьютерная лингвистика сегодня: от исследований языка до киберспорта](https://youtu.be/sjDAdHPDtkc).\n",
    "\n",
    "Вкратце разница такова:\n",
    "- Теоретическая лингвистика занимается теоретическими (внезапно!) исследованиями. Теоретические лингвисты изучают язык в поле (в экспедициях) или с помощью корпусов. Даже теоретические лингвисты (современные) пользуются средствами автоматической обработки естественного языка! Питон многим из них облегчает жизнь: достаточно почитать последние научные статьи в журналах или осведомиться, какие диссертации защищались в последние годы. \n",
    "- NLP - это когда **инженеры** создают связанные с языком приложения преимущественно для бизнеса. Например, делают программу, которая позволяет автоматически обрабатывать кучи документов, или улучшают поисковые сервисы (или делают рекомендательные сервисы, или что угодно). \n",
    "- Компьютерная лингвистика - это когда **лингвисты** пользуются инструментами инженеров, такими, как нейронные сети, базы данных и т.д., чтобы изучать язык с теоретической точки зрения. \n",
    "\n",
    "Какой бы путь вы ни выбрали в дальнейшем, умение программировать пригодится... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3f442-eed6-448a-853e-1d786c1f4023",
   "metadata": {},
   "source": [
    "В современном мире КЛ существует несколько базовых терминов, которые стоит знать всем. \n",
    "\n",
    "- Пайплайн: план действий, которые нужно выполнить, чтобы решить задачу. Например, если нам нужно собрать теоретический корпус языка, такой, как ГИКРЯ, нам нужно собрать и обработать тексты, разметить их и сделать так, чтобы по ним можно было искать. \n",
    "- Бейзлайн (есть вариант бейслайн): это базовое, самое очевидное решение какой-то задачи; самое первое, которое приходит в голову. Обычно от бейзлайна отталкиваются, когда хотят улучшить решение. Например, если у нас есть задача определять тональность текста (хороший/плохой отзыв), то самое простое - посчитать количество слов типа \"понравилось\\не понравилось\"; это будет бейзлайн, который будет с маленькой точностью эту задачу решать. Но на него уже можно равняться. \n",
    "- Датасет: набор данных для решения задачи. В нашем случае датасет обычно == корпус: для решения задач КЛ и NLP берутся наборы текстов, размеченных или нет. Размеченные датасеты на вес золота!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5840e-19cd-4c9e-84e8-0b12834ff99b",
   "metadata": {},
   "source": [
    "Задачи NLP - это не просто какие-то там задачи, которые человек решил и забыл: это задачи очень сложные, про некоторые из них (как задача машинного перевода) вообще долгое время думали, что у них нет решения. Соответственно, этот набор задач живет и здравствует, а цель инженеров - улучшать существующие решения. Какие есть примеры таких \"вечных\" задач?\n",
    "- самая первая, пожалуй: машинный перевод. МП очень увлекались в 60-х, теория \"Смысл-Текст\" возникла именно из-за того, что в СССР много вкладывались в машинный перевод. К концу века люди серьезно разочаровались в МП, одно время верили, что невозможно эту задачу решить. Переворот случился, когда появились нейронные сети. Все современные переводчики - на них; вы можете сами заметить, что перевод того же гугла улучшается изо дня в день. \n",
    "- анализ тональности текста: дан миллион отзывов на продукт, требуется выяснить, сколько из них положительные, а сколько отрицательные, а в идеале еще и вычленить, к чему люди придираются и что хвалят. \n",
    "- извлечение именованных сущностей: в тексте встречаются имена собственные, даты, цены и т.п. Нужно автоматически их все вычленить. \n",
    "- извлечение отношений: а теперь не просто вычленить именованные сущности, но и понять, кто кому сват и брат (кто, что, за сколько и когда купил/продал). \n",
    "- генерация текста: Балабоба. Другие разновидности - генерация кода (!), генерация рецептов и миллион других вещей. Очень интересное!\n",
    "- саммаризация: есть \"Война и мир\", школьник хочет саммари. Машины умеют это!\n",
    "- упрощение текста: есть сложная научная статья, машина умеет ее переводить на человеческий язык. \n",
    "- автоматический бан троллей и провокаторов в интернете: вычленить из постов пользователя мат, забанить его: машина умеет это!\n",
    "\n",
    "...\n",
    "\n",
    "Задач, как мы видим, много. У них свои собственные пайплайны и методы, но примерно все задачи, где для решения нужен текст, требуют этот текст обрабатывать определенным образом. Тут уже на сцену выходим мы, лингвисты. Во-первых, наши коллеги из физтеха, которые занимаются именно NLP, ничего так не любят, как просить студентов РГГУ разметить им вот еще один маленький тут датасетик. Во-вторых, некоторые виды разметки так сложны, что без парочки лингвистов и не обойтись: например, синтаксическая или семантическая разметка. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2352a6c-cec4-4fe7-baf9-a8ed2a569143",
   "metadata": {},
   "source": [
    "Таким образом, для сбора датасетов существует приблизительно один общий пайплайн (некоторые задачи требуют все перечисленные шаги, другие нет). Как собирать датасет? (в частности, корпус) В том числе для ваших собственных теоретических изысканий. \n",
    "\n",
    "1. Необходимо получить данные. В связи этим есть такие термины, как краулинг (crawling) и скрейпинг (scraping). Тексты мы сегодня получаем преимущественно из интернета и полностью автоматически. Самая известная программа для краулинга - Apache Nutch; на ваше счастье, мы не будем учиться ей пользоваться. Есть и программы попроще, типа twint для скрейпинга твиттера, и у многих сайтов, например, у Википедии, есть собственный API (интерфейс для взаимодействия между двумя программами, в отличие от UI - интерфейса между человеком и программой). Если вам когда-нибудь понадобится выкачать тексты, можно воспользоваться этим сакральным знанием: для многих популярных ресурсов типа телеграма люди давно понаписали очень простых в использовании библиотек, например, для Вики есть wikipedia-api (но у Вики, кстати, есть и готовые дампы, которые можно получить по адресу: [тут](https://dumps.wikimedia.org/). Дело за малым: распарсить xml-разметку...). \n",
    "2. В зависимости от вашей удачи и старания написавших библиотеки людей, вышеназванные краулеры/скрейперы выкачивают текст либо уже готовеньким для обработки (но и то его обычно приходится *нормализовать*, то есть, выкидывать ссылки, смайлики и тому подобное), либо as is: со всей html-обвязкой и прочим бойлерплейтом (boilerplate - стандартизованный шаблонный текст, например, тексты в табличках Википедии, которые перечисляют, что нужно указать на странице). Тексты обычно приходится потом чистить: самый известный инструмент для вытаскивания текста из html - beautifulsoup4. Иногда дополнительно приходится удалять дубли (копипасту) и даже вообще отфильтровывать спам (для этого создаются собственные инструменты, обычно на нейронных сетях). \n",
    "3. Вот наконец мы получили гигантский набор текстовых файликов, внутри которых содержатся сырые тексты! Что теперь с ними делать? Компьютер не понимает, где в этих текстах слова и предложения: для него это только набор символов. Значит, уже лингвистическая задача - разделить эти тексты на предложения и потом на **токены**. \n",
    "\n",
    "        Токен - это значимая для анализа последовательность символов. Не обязательно слово и знак пунктуации: например, современные нейронные сети внутри себя делят тексты на подслова, которые нам кажутся бессмысленными. Нейронка может разделить слово \"Сингапура\" как \"Сингапур - а\", а может как \"С - и - нга - пур - а\"... real story. \n",
    "        \n",
    "4. Дальше уже может понадобиться более сложный анализ текстов: морфологическая, синтаксическая, семантическая разметка. Ничего из этого сегодня обычно не делают вручную. Мы с вами посмотрим, как автоматически делать морфологический и синтаксический разбор. \n",
    "\n",
    "5. В качестве вишенки на торте можно устроить еще какую-нибудь разметку: выделить в тексте именованные сущности, референтные связи и так далее, но это уже в зависимости от задачи. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de222f-7ab2-44ca-90f0-494b8e7f0f61",
   "metadata": {},
   "source": [
    "Поскольку все это - вещи, которыми люди занимаются уже довольно давно, существует просто *огромное* количество готовых инструментов, в том числе большие комплексные библиотеки; подавляющее большинство этих инструментов написано для питона! Поэтому мы его и изучаем. (Точнее говоря, написаны они обычно в каких-нибудь С или Java, но добрые люди понаделали \"оберток\" под питон). \n",
    "\n",
    "Большие библиотеки, о которых стоит знать:\n",
    "- NLTK: самая, пожалуй, старая и известная. \n",
    "- TextBlob: тот же NLTK, только в профиль. \n",
    "- spaCy: более современный вариант NTLK на Cython (что это, можно не знать. :)\n",
    "- DeepPavlov: скорее заточенная под нужды инженеров библиотека, которую разрабатывают в МФТИ. Для русского языка! (все вышеназванные мультиязычные)\n",
    "- natasha: тоже сделана для русского языка, очень быстрая, достаточно качественная. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655881d-efb1-4332-a073-31089bcb10a1",
   "metadata": {},
   "source": [
    "Последнее, о чем стоит знать - это принципы, на которых базируются наши инструменты. На чем может работать инструмент автоматической обработки естественного языка:\n",
    "1. На правилах: человек сам прописывает лес ифов. Плюс правиловых инструментов: вы всегда точно знаете, как он будет работать. А еще он будет быстрый, как понос. Минус: невозможно предусмотреть вообще ВСЕ, трудно дорабатывать, качество работы обычно самое низкое. \n",
    "2. С использованием статистических (вероятностных) методов: мы все еще понимаем, как и почему работает наш инструмент, но уже вместо правилок используем теорию вероятности. Ну типа, с какой вероятностью после предлога будет идти глагол?..\n",
    "3. С использованием алгоритмов машинного обучения: уже не очень хорошо понимаем, что происходит внутри у нашего инструмента (а кстати, он стал медленнее...), но точно знаем, какие данные нужно ему скормить, чтобы он работал лучше. Машинное обучение - это когда мы показываем компьютеру, как надо правильно делать, а он пытается сам по хитрым математическим формулам вычислить ответы на основании того, что видел. \n",
    "4. На нейронных сетях: абсолютно не понимаем, что происходит у нашего инструмента внутри, и работает он, как черепаха. Зато ему достаточно скормить примерчики, как правильно решать задачу, и он будет удивительно качественно ее решать! Чем больше данных для обучения, тем качественнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23e789-46b2-4c63-aaaf-2577ecb2781f",
   "metadata": {},
   "source": [
    "Большинство современных задач (подавляющее) уже решается только нейронными сетями: язык - вещь непростая, и морфологию или синтаксис правилами сегодня размечают только безумцы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08eda8-b09e-4938-9035-b88236ca3298",
   "metadata": {},
   "source": [
    "#### Токенизация и сегментация по предложениям"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663b0a9-fe86-4ded-bf08-add79182d417",
   "metadata": {},
   "source": [
    "И то, и другое - очень базовые задачи; токенизаторы и сегментаторы включены во все крупные лингвистические библиотеки. \n",
    "\n",
    "Поскольку разделять текст на слова и предложения вроде бы очень легко, как правило, используются инструменты на правилах; хотя и не для каждого языка это верно: для языков, у которых слова не отделяются пробелами, токенизаторы могут быть нейронными. Кстати, неплохо вспомнить, что мы сами не всегда знаем, что мы хотим считать за слово. Что мы хотим считать за токен - другой вопрос: токен определяется задачами. Например, для определенной задачи мы можем хотеть считать, что \"бледно-зеленый\" - это два отдельных слова, а для другой - нет. \n",
    "\n",
    "Самый простой токенизатор вы в состоянии написать сами (что мы на занятии и делали). Иногда это бывает даже хорошо и полезно, потому что про свой токенизатор вы точно знаете, как он работает. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad589598-bbb9-4453-b5a8-b3c48a780dfe",
   "metadata": {},
   "source": [
    "1. Сентенайзеры:\n",
    "\n",
    "        pip install razdel\n",
    "        pip install rusenttokenize\n",
    "        \n",
    "\n",
    "razdel - подмодуль Наташи; rusenttokenize - подмодуль DeepPavlov. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f91b1e-d2fb-4197-ad5c-e6d97117ea54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Буллом-со (ммани, мандинги) — один из атлантических языков нигеро-конголезской макросемьи.',\n",
       " 'Распространён в прибрежных районах, возле границы между Гвинеей и Сьерра-Леоне.',\n",
       " 'По данным справочника Ethnologue число носителей составляет 8350 человек в Сьерра-Леоне и несколько человек в Гвинее, другие источники сообщают о гораздо меньшем количестве носителей (около 500 чел).',\n",
       " 'Наиболее близкородственный язык — бом, имеется небольшая взаимопонимаемость с шербро.',\n",
       " 'Буллом-со активно вытесняется соседними языками, главным образом — темне.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import sentenize\n",
    "\n",
    "raw = '''Буллом-со (ммани, мандинги) — один из атлантических языков нигеро-конголезской макросемьи. Распространён в прибрежных районах, возле границы между Гвинеей и Сьерра-Леоне. По данным справочника Ethnologue число носителей составляет 8350 человек в Сьерра-Леоне и несколько человек в Гвинее, другие источники сообщают о гораздо меньшем количестве носителей (около 500 чел). Наиболее близкородственный язык — бом, имеется небольшая взаимопонимаемость с шербро. Буллом-со активно вытесняется соседними языками, главным образом — темне.'''\n",
    "\n",
    "sents = [s.text for s in sentenize(raw)]\n",
    "\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a74bd-aaa6-44be-9893-06480409f122",
   "metadata": {},
   "source": [
    "Для чего нам тут нужен генератор? Дело в том, что sentenize работает примерно как finditer: возвращает итератор из набора специальных объектов, очень похожих на Match из re, в которых содержится сам текст предложения + индексы его начала и конца в исходной строке. Обычно эти индексы никому не нужны, поэтому результат тут же пересобирывается в список строк. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d3e838d-1eda-45cc-bd51-e8230e5a4860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Буллом-со (ммани, мандинги) — один из атлантических языков нигеро-конголезской макросемьи.',\n",
       " 'Распространён в прибрежных районах, возле границы между Гвинеей и Сьерра-Леоне.',\n",
       " 'По данным справочника Ethnologue число носителей составляет 8350 человек в Сьерра-Леоне и несколько человек в Гвинее, другие источники сообщают о гораздо меньшем количестве носителей (около 500 чел).',\n",
       " 'Наиболее близкородственный язык — бом, имеется небольшая взаимопонимаемость с шербро.',\n",
       " 'Буллом-со активно вытесняется соседними языками, главным образом — темне.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n",
    "\n",
    "sents = ru_sent_tokenize(raw)\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11ba39-b3a7-459d-9ac6-b7bf282cd44e",
   "metadata": {},
   "source": [
    "На таком простом примере оба сентенайзера работают одинаково, но советую поэкспериментировать с более сложными текстами. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3336f-cd3e-4072-a246-b90bccc228e4",
   "metadata": {},
   "source": [
    "2. Токенизаторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "141ab447-e519-4f6f-ae5f-60c2a85e5110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Буллом-со',\n",
       " '(',\n",
       " 'ммани',\n",
       " ',',\n",
       " 'мандинги',\n",
       " ')',\n",
       " '—',\n",
       " 'один',\n",
       " 'из',\n",
       " 'атлантических',\n",
       " 'языков',\n",
       " 'нигеро-конголезской',\n",
       " 'макросемьи',\n",
       " '.',\n",
       " 'Распространён',\n",
       " 'в',\n",
       " 'прибрежных',\n",
       " 'районах',\n",
       " ',',\n",
       " 'возле',\n",
       " 'границы',\n",
       " 'между',\n",
       " 'Гвинеей',\n",
       " 'и',\n",
       " 'Сьерра-Леоне',\n",
       " '.',\n",
       " 'По',\n",
       " 'данным',\n",
       " 'справочника',\n",
       " 'Ethnologue',\n",
       " 'число',\n",
       " 'носителей',\n",
       " 'составляет',\n",
       " '8350',\n",
       " 'человек',\n",
       " 'в',\n",
       " 'Сьерра-Леоне',\n",
       " 'и',\n",
       " 'несколько',\n",
       " 'человек',\n",
       " 'в',\n",
       " 'Гвинее',\n",
       " ',',\n",
       " 'другие',\n",
       " 'источники',\n",
       " 'сообщают',\n",
       " 'о',\n",
       " 'гораздо',\n",
       " 'меньшем',\n",
       " 'количестве',\n",
       " 'носителей',\n",
       " '(',\n",
       " 'около',\n",
       " '500',\n",
       " 'чел',\n",
       " ')',\n",
       " '.',\n",
       " 'Наиболее',\n",
       " 'близкородственный',\n",
       " 'язык',\n",
       " '—',\n",
       " 'бом',\n",
       " ',',\n",
       " 'имеется',\n",
       " 'небольшая',\n",
       " 'взаимопонимаемость',\n",
       " 'с',\n",
       " 'шербро',\n",
       " '.',\n",
       " 'Буллом-со',\n",
       " 'активно',\n",
       " 'вытесняется',\n",
       " 'соседними',\n",
       " 'языками',\n",
       " ',',\n",
       " 'главным',\n",
       " 'образом',\n",
       " '—',\n",
       " 'темне',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = [t.text for t in tokenize(raw)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fde70-1758-46e4-bdd5-6e22b13f9cb5",
   "metadata": {},
   "source": [
    "Это один из самых быстрых токенизаторов для русского языка, и довольно качественный. Устроен он точно так же, как их сентенайзер. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d1faa-b121-461d-8ab1-4387dc4d55b0",
   "metadata": {},
   "source": [
    "**Токенизация и сегментация в крупных библиотеках**\n",
    "\n",
    "1. NLTK:\n",
    "\n",
    "        !pip install nltk\n",
    "        import nltk\n",
    "        nltk.download()\n",
    "        \n",
    "2. SpaCy:\n",
    "\n",
    "        !pip install spacy \n",
    "        \n",
    "SpaCy поддерживает несколько разных языков. Посмотреть языки можно в [документации](https://spacy.io/models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb9ee01-42c3-46c7-a9da-d23ba8e211bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Буллом', 'со', 'ммани', 'мандинги', 'один', 'из', 'атлантических', 'языков', 'нигеро', 'конголезской', 'макросемьи', 'Распространён', 'в', 'прибрежных', 'районах', 'возле', 'границы', 'между', 'Гвинеей', 'и', 'Сьерра', 'Леоне', 'По', 'данным', 'справочника', 'Ethnologue', 'число', 'носителей', 'составляет', '8350', 'человек', 'в', 'Сьерра', 'Леоне', 'и', 'несколько', 'человек', 'в', 'Гвинее', 'другие', 'источники', 'сообщают', 'о', 'гораздо', 'меньшем', 'количестве', 'носителей', 'около', '500', 'чел', 'Наиболее', 'близкородственный', 'язык', 'бом', 'имеется', 'небольшая', 'взаимопонимаемость', 'с', 'шербро', 'Буллом', 'со', 'активно', 'вытесняется', 'соседними', 'языками', 'главным', 'образом', 'темне']\n",
      "['Буллом-со', '(', 'ммани', ',', 'мандинги', ')', '—', 'один', 'из', 'атлантических', 'языков', 'нигеро-конголезской', 'макросемьи', '.', 'Распространён', 'в', 'прибрежных', 'районах', ',', 'возле', 'границы', 'между', 'Гвинеей', 'и', 'Сьерра-Леоне', '.', 'По', 'данным', 'справочника', 'Ethnologue', 'число', 'носителей', 'составляет', '8350', 'человек', 'в', 'Сьерра-Леоне', 'и', 'несколько', 'человек', 'в', 'Гвинее', ',', 'другие', 'источники', 'сообщают', 'о', 'гораздо', 'меньшем', 'количестве', 'носителей', '(', 'около', '500', 'чел', ')', '.', 'Наиболее', 'близкородственный', 'язык', '—', 'бом', ',', 'имеется', 'небольшая', 'взаимопонимаемость', 'с', 'шербро', '.', 'Буллом-со', 'активно', 'вытесняется', 'соседними', 'языками', ',', 'главным', 'образом', '—', 'темне', '.']\n",
      "['Буллом-со (ммани, мандинги) — один из атлантических языков нигеро-конголезской макросемьи.', 'Распространён в прибрежных районах, возле границы между Гвинеей и Сьерра-Леоне.', 'По данным справочника Ethnologue число носителей составляет 8350 человек в Сьерра-Леоне и несколько человек в Гвинее, другие источники сообщают о гораздо меньшем количестве носителей (около 500 чел).', 'Наиболее близкородственный язык — бом, имеется небольшая взаимопонимаемость с шербро.', 'Буллом-со активно вытесняется соседними языками, главным образом — темне.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+')\n",
    "print(tokenizer.tokenize(raw))\n",
    "print(word_tokenize(raw))\n",
    "print(sent_tokenize(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "485c4b74-deb9-41ff-a5eb-5cd197eb7840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Буллом', '-', 'со', '(', 'ммани', ',', 'мандинги', ')', '—', 'один', 'из', 'атлантических', 'языков', 'нигеро', '-', 'конголезской', 'макросемьи', '.', 'Распространён', 'в', 'прибрежных', 'районах', ',', 'возле', 'границы', 'между', 'Гвинеей', 'и', 'Сьерра', '-', 'Леоне', '.', 'По', 'данным', 'справочника', 'Ethnologue', 'число', 'носителей', 'составляет', '8350', 'человек', 'в', 'Сьерра', '-', 'Леоне', 'и', 'несколько', 'человек', 'в', 'Гвинее', ',', 'другие', 'источники', 'сообщают', 'о', 'гораздо', 'меньшем', 'количестве', 'носителей', '(', 'около', '500', 'чел', ')', '.', 'Наиболее', 'близкородственный', 'язык', '—', 'бом', ',', 'имеется', 'небольшая', 'взаимопонимаемость', 'с', 'шербро', '.', 'Буллом', '-', 'со', 'активно', 'вытесняется', 'соседними', 'языками', ',', 'главным', 'образом', '—', 'темне', '.']\n",
      "['Буллом-со (ммани, мандинги) — один из атлантических языков нигеро-конголезской макросемьи.', 'Распространён в прибрежных районах, возле границы между Гвинеей и Сьерра-Леоне.', 'По данным справочника Ethnologue число носителей составляет 8350 человек в Сьерра-Леоне и несколько человек в Гвинее, другие источники сообщают о гораздо меньшем количестве носителей (около 500 чел).', 'Наиболее близкородственный язык — бом, имеется небольшая взаимопонимаемость с шербро.', 'Буллом-со активно вытесняется соседними языками, главным образом — темне.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('ru')\n",
    "nlp.add_pipe('sentencizer')\n",
    "doc = nlp(raw) # в этот момент спейси предобрабатывает наш сырой текст \n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)\n",
    "sents = [sent.text for sent in doc.sents]\n",
    "print(sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
